{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "claran_skasdc1_example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ICRAR/skasdc1/blob/master/claran_skasdc1_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xh1ENnDxJDi8",
        "colab_type": "code",
        "outputId": "0fe164a7-8308-4008-b02f-34c3958777ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        }
      },
      "source": [
        "!pip install --upgrade git+https://github.com/tensorpack/tensorpack.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/tensorpack/tensorpack.git\n",
            "  Cloning https://github.com/tensorpack/tensorpack.git to /tmp/pip-req-build-1alvy0ly\n",
            "  Running command git clone -q https://github.com/tensorpack/tensorpack.git /tmp/pip-req-build-1alvy0ly\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from tensorpack==0.9.8) (1.17.3)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from tensorpack==0.9.8) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from tensorpack==0.9.8) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from tensorpack==0.9.8) (0.8.5)\n",
            "Collecting tqdm>4.29.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/f2/764a5d530cf143ded9bc95216edb6e258c6554511e78de7c250557e8f3ed/tqdm-4.37.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: msgpack>=0.5.2 in /usr/local/lib/python3.6/dist-packages (from tensorpack==0.9.8) (0.5.6)\n",
            "Collecting msgpack-numpy>=0.4.4.2\n",
            "  Downloading https://files.pythonhosted.org/packages/c8/ab/09904a909bccc471f219fb8f5d0838cbcb10cc26089a2b29e84c893e216e/msgpack_numpy-0.4.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: pyzmq>=16 in /usr/local/lib/python3.6/dist-packages (from tensorpack==0.9.8) (17.0.0)\n",
            "Requirement already satisfied, skipping upgrade: psutil>=5 in /usr/local/lib/python3.6/dist-packages (from tensorpack==0.9.8) (5.4.8)\n",
            "Building wheels for collected packages: tensorpack\n",
            "  Building wheel for tensorpack (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorpack: filename=tensorpack-0.9.8-py2.py3-none-any.whl size=291856 sha256=f88e068fcc1deb5882d3b19d0dfe0e363e885d0ee51ed471158fa68084cdbcdc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-2rtufdz0/wheels/d1/88/84/9f91acd55f34d585f7d6742cb13925a6051f82f6075aa6a0a9\n",
            "Successfully built tensorpack\n",
            "Installing collected packages: tqdm, msgpack-numpy, tensorpack\n",
            "  Found existing installation: tqdm 4.28.1\n",
            "    Uninstalling tqdm-4.28.1:\n",
            "      Successfully uninstalled tqdm-4.28.1\n",
            "Successfully installed msgpack-numpy-0.4.4.3 tensorpack-0.9.8 tqdm-4.37.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wg6oP4wIJH5W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "af80d9ae-c176-4ec0-d4d8-202afd4cc2ff"
      },
      "source": [
        "from tensorpack.utils import logger"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1RsPl3-JnS4",
        "colab_type": "code",
        "outputId": "1bc4f650-19ff-4cbf-f5bb-b7a02f9add78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpYA6PfaOF4z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRZ4NCe6OG20",
        "colab_type": "code",
        "outputId": "e9f65121-fa15-4388-c41c-f3107a6567d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "% cd /content/drive/My\\ Drive/skasdc1"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/skasdc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8awAx9kbQM2i",
        "colab_type": "code",
        "outputId": "4b2af2d6-5647-4425-e8a0-06ca99a2a3cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "!wget -O /tmp/ImageNet-R50-AlignPadding.npz http://models.tensorpack.com/FasterRCNN/ImageNet-R50-AlignPadding.npz"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-07 07:58:35--  http://models.tensorpack.com/FasterRCNN/ImageNet-R50-AlignPadding.npz\n",
            "Resolving models.tensorpack.com (models.tensorpack.com)... 185.207.105.29\n",
            "Connecting to models.tensorpack.com (models.tensorpack.com)|185.207.105.29|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 95179737 (91M) [application/octet-stream]\n",
            "Saving to: ‘/tmp/ImageNet-R50-AlignPadding.npz’\n",
            "\n",
            "\r          /tmp/Imag   0%[                    ]       0  --.-KB/s               \r         /tmp/Image  17%[==>                 ]  15.77M  78.9MB/s               \r        /tmp/ImageN  41%[=======>            ]  37.86M  94.6MB/s               \r       /tmp/ImageNe  66%[============>       ]  60.25M   100MB/s               \r      /tmp/ImageNet  90%[=================>  ]  82.55M   103MB/s               \r/tmp/ImageNet-R50-A 100%[===================>]  90.77M   104MB/s    in 0.9s    \n",
            "\n",
            "2019-11-07 07:58:36 (104 MB/s) - ‘/tmp/ImageNet-R50-AlignPadding.npz’ saved [95179737/95179737]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhjArIE-NzUk",
        "colab_type": "code",
        "outputId": "3fff9526-90e6-450e-d26c-65f09f58e3e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "! git clone https://github.com/chenwuperth/claran.git"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'claran'...\n",
            "remote: Enumerating objects: 22, done.\u001b[K\n",
            "remote: Counting objects:   4% (1/22)\u001b[K\rremote: Counting objects:   9% (2/22)\u001b[K\rremote: Counting objects:  13% (3/22)\u001b[K\rremote: Counting objects:  18% (4/22)\u001b[K\rremote: Counting objects:  22% (5/22)\u001b[K\rremote: Counting objects:  27% (6/22)\u001b[K\rremote: Counting objects:  31% (7/22)\u001b[K\rremote: Counting objects:  36% (8/22)\u001b[K\rremote: Counting objects:  40% (9/22)\u001b[K\rremote: Counting objects:  45% (10/22)\u001b[K\rremote: Counting objects:  50% (11/22)\u001b[K\rremote: Counting objects:  54% (12/22)\u001b[K\rremote: Counting objects:  59% (13/22)\u001b[K\rremote: Counting objects:  63% (14/22)\u001b[K\rremote: Counting objects:  68% (15/22)\u001b[K\rremote: Counting objects:  72% (16/22)\u001b[K\rremote: Counting objects:  77% (17/22)\u001b[K\rremote: Counting objects:  81% (18/22)\u001b[K\rremote: Counting objects:  86% (19/22)\u001b[K\rremote: Counting objects:  90% (20/22)\u001b[K\rremote: Counting objects:  95% (21/22)\u001b[K\rremote: Counting objects: 100% (22/22)\u001b[K\rremote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects:   6% (1/15)\u001b[K\rremote: Compressing objects:  13% (2/15)\u001b[K\rremote: Compressing objects:  20% (3/15)\u001b[K\rremote: Compressing objects:  26% (4/15)\u001b[K\rremote: Compressing objects:  33% (5/15)\u001b[K\rremote: Compressing objects:  40% (6/15)\u001b[K\rremote: Compressing objects:  46% (7/15)\u001b[K\rremote: Compressing objects:  53% (8/15)\u001b[K\rremote: Compressing objects:  60% (9/15)\u001b[K\rremote: Compressing objects:  66% (10/15)\u001b[K\rremote: Compressing objects:  73% (11/15)\u001b[K\rremote: Compressing objects:  80% (12/15)\u001b[K\rremote: Compressing objects:  86% (13/15)\u001b[K\rremote: Compressing objects:  93% (14/15)\u001b[K\rremote: Compressing objects: 100% (15/15)\u001b[K\rremote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "Receiving objects:   0% (1/150)   \rReceiving objects:   1% (2/150)   \rReceiving objects:   2% (3/150)   \rReceiving objects:   3% (5/150)   \rReceiving objects:   4% (6/150)   \rReceiving objects:   5% (8/150)   \rReceiving objects:   6% (9/150)   \rReceiving objects:   7% (11/150)   \rReceiving objects:   8% (12/150)   \rReceiving objects:   9% (14/150)   \rReceiving objects:  10% (15/150)   \rReceiving objects:  11% (17/150)   \rReceiving objects:  12% (18/150)   \rReceiving objects:  13% (20/150)   \rReceiving objects:  14% (21/150)   \rReceiving objects:  15% (23/150)   \rReceiving objects:  16% (24/150)   \rReceiving objects:  17% (26/150)   \rReceiving objects:  18% (27/150)   \rReceiving objects:  19% (29/150)   \rReceiving objects:  20% (30/150)   \rReceiving objects:  21% (32/150)   \rReceiving objects:  22% (33/150)   \rReceiving objects:  23% (35/150)   \rReceiving objects:  24% (36/150)   \rReceiving objects:  25% (38/150)   \rReceiving objects:  26% (39/150)   \rReceiving objects:  27% (41/150)   \rReceiving objects:  28% (42/150)   \rReceiving objects:  29% (44/150)   \rReceiving objects:  30% (45/150)   \rReceiving objects:  31% (47/150)   \rReceiving objects:  32% (48/150)   \rReceiving objects:  33% (50/150)   \rReceiving objects:  34% (51/150)   \rReceiving objects:  35% (53/150)   \rReceiving objects:  36% (54/150)   \rReceiving objects:  37% (56/150)   \rReceiving objects:  38% (57/150)   \rReceiving objects:  39% (59/150)   \rReceiving objects:  40% (60/150)   \rReceiving objects:  41% (62/150)   \rReceiving objects:  42% (63/150)   \rReceiving objects:  43% (65/150)   \rReceiving objects:  44% (66/150)   \rReceiving objects:  45% (68/150)   \rReceiving objects:  46% (69/150)   \rReceiving objects:  47% (71/150)   \rReceiving objects:  48% (72/150)   \rReceiving objects:  49% (74/150)   \rReceiving objects:  50% (75/150)   \rReceiving objects:  51% (77/150)   \rReceiving objects:  52% (78/150)   \rReceiving objects:  53% (80/150)   \rReceiving objects:  54% (81/150)   \rReceiving objects:  55% (83/150)   \rReceiving objects:  56% (84/150)   \rReceiving objects:  57% (86/150)   \rReceiving objects:  58% (87/150)   \rReceiving objects:  59% (89/150)   \rReceiving objects:  60% (90/150)   \rReceiving objects:  61% (92/150)   \rReceiving objects:  62% (93/150)   \rReceiving objects:  63% (95/150)   \rReceiving objects:  64% (96/150)   \rReceiving objects:  65% (98/150)   \rReceiving objects:  66% (99/150)   \rReceiving objects:  67% (101/150)   \rReceiving objects:  68% (102/150)   \rReceiving objects:  69% (104/150)   \rReceiving objects:  70% (105/150)   \rReceiving objects:  71% (107/150)   \rReceiving objects:  72% (108/150)   \rReceiving objects:  73% (110/150)   \rReceiving objects:  74% (111/150)   \rReceiving objects:  75% (113/150)   \rReceiving objects:  76% (114/150)   \rReceiving objects:  77% (116/150)   \rReceiving objects:  78% (117/150)   \rReceiving objects:  79% (119/150)   \rReceiving objects:  80% (120/150)   \rReceiving objects:  81% (122/150)   \rReceiving objects:  82% (123/150)   \rReceiving objects:  83% (125/150)   \rReceiving objects:  84% (126/150)   \rReceiving objects:  85% (128/150)   \rReceiving objects:  86% (129/150)   \rReceiving objects:  87% (131/150)   \rReceiving objects:  88% (132/150)   \rReceiving objects:  89% (134/150)   \rReceiving objects:  90% (135/150)   \rReceiving objects:  91% (137/150)   \rReceiving objects:  92% (138/150)   \rReceiving objects:  93% (140/150)   \rReceiving objects:  94% (141/150)   \rReceiving objects:  95% (143/150)   \rremote: Total 150 (delta 10), reused 17 (delta 7), pack-reused 128\n",
            "Receiving objects:  96% (144/150)   \rReceiving objects:  97% (146/150)   \rReceiving objects:  98% (147/150)   \rReceiving objects:  99% (149/150)   \rReceiving objects: 100% (150/150)   \rReceiving objects: 100% (150/150), 139.63 KiB | 812.00 KiB/s, done.\n",
            "Resolving deltas:   0% (0/83)   \rResolving deltas:   2% (2/83)   \rResolving deltas:   6% (5/83)   \rResolving deltas:   7% (6/83)   \rResolving deltas:  13% (11/83)   \rResolving deltas:  16% (14/83)   \rResolving deltas:  28% (24/83)   \rResolving deltas:  37% (31/83)   \rResolving deltas:  40% (34/83)   \rResolving deltas:  42% (35/83)   \rResolving deltas:  43% (36/83)   \rResolving deltas:  44% (37/83)   \rResolving deltas:  45% (38/83)   \rResolving deltas:  46% (39/83)   \rResolving deltas:  48% (40/83)   \rResolving deltas:  49% (41/83)   \rResolving deltas:  62% (52/83)   \rResolving deltas:  63% (53/83)   \rResolving deltas:  65% (54/83)   \rResolving deltas:  67% (56/83)   \rResolving deltas:  81% (68/83)   \rResolving deltas:  91% (76/83)   \rResolving deltas: 100% (83/83)   \rResolving deltas: 100% (83/83), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zfDkqm9Otl1",
        "colab_type": "code",
        "outputId": "efb2e6a1-cbbf-4b26-b6be-ea4c2c41b053",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "! ls"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "claran\tdata\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvW5EDc2Ow3j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir train_logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIgyBQUYPMzm",
        "colab_type": "code",
        "outputId": "b66170ab-b97d-40f4-e9d8-928f1f8ec2cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "% cd claran"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/skasdc1/claran\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oJQmeT97d2m",
        "colab_type": "text"
      },
      "source": [
        "It will take a few hours to finish training. We stopped it at Epoch 3 for an illustration here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBF9JLlZPjBh",
        "colab_type": "code",
        "outputId": "153f6d94-2930-4a07-99fe-c7327ed9be94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python train.py --logdir ../train_logs/ --config \\\n",
        "        MODE_MASK=False MODE_FPN=True \\\n",
        "        DATA.BASEDIR=../data \\\n",
        "        BACKBONE.WEIGHTS=/tmp/ImageNet-R50-AlignPadding.npz \\\n",
        "        DATA.TRAIN=train_B1_1000h DATA.VAL=val_B1_1000h \\\n",
        "        PREPROC.TRAIN_SHORT_EDGE_SIZE=600,600 \\\n",
        "        PREPROC.TEST_SHORT_EDGE_SIZE=600 \\\n",
        "\t      TRAIN.LR_SCHEDULE=5000,6000,7000 \\\n",
        "        DATA.CLASS_NAMES=1,2,3"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1107 08:03:32 @logger.py:90]\u001b[0m Argv: train.py --logdir ../train_logs/ --config MODE_MASK=False MODE_FPN=True DATA.BASEDIR=../data BACKBONE.WEIGHTS=/tmp/ImageNet-R50-AlignPadding.npz DATA.TRAIN=train_B1_1000h DATA.VAL=val_B1_1000h PREPROC.TRAIN_SHORT_EDGE_SIZE=600,600 PREPROC.TEST_SHORT_EDGE_SIZE=600 TRAIN.LR_SCHEDULE=5000,6000,7000 DATA.CLASS_NAMES=1,2,3\n",
            "\u001b[32m[1107 08:03:32 @config.py:285]\u001b[0m Config: ------------------------------------------\n",
            "{'BACKBONE': {'FREEZE_AFFINE': False,\n",
            "              'FREEZE_AT': 2,\n",
            "              'NORM': 'FreezeBN',\n",
            "              'RESNET_NUM_BLOCKS': [3, 4, 6, 3],\n",
            "              'STRIDE_1X1': False,\n",
            "              'TF_PAD_MODE': False,\n",
            "              'WEIGHTS': '/tmp/ImageNet-R50-AlignPadding.npz'},\n",
            " 'CASCADE': {'BBOX_REG_WEIGHTS': [[10.0, 10.0, 5.0, 5.0], [20.0, 20.0, 10.0, 10.0],\n",
            "                                  [30.0, 30.0, 15.0, 15.0]],\n",
            "             'IOUS': [0.5, 0.6, 0.7]},\n",
            " 'DATA': {'BASEDIR': '../data',\n",
            "          'CLASS_NAMES': ['BG', '1', '2', '3'],\n",
            "          'NUM_CATEGORY': 3,\n",
            "          'NUM_CLASS': 4,\n",
            "          'TRAIN': ['train_B1_1000h'],\n",
            "          'VAL': ('val_B1_1000h',)},\n",
            " 'FPN': {'ANCHOR_STRIDES': (4, 8, 16, 32, 64),\n",
            "         'CASCADE': False,\n",
            "         'FRCNN_CONV_HEAD_DIM': 256,\n",
            "         'FRCNN_FC_HEAD_DIM': 1024,\n",
            "         'FRCNN_HEAD_FUNC': 'fastrcnn_2fc_head',\n",
            "         'MRCNN_HEAD_FUNC': 'maskrcnn_up4conv_head',\n",
            "         'NORM': 'None',\n",
            "         'NUM_CHANNEL': 256,\n",
            "         'PROPOSAL_MODE': 'Level',\n",
            "         'RESOLUTION_REQUIREMENT': 32},\n",
            " 'FRCNN': {'BATCH_PER_IM': 512,\n",
            "           'BBOX_REG_WEIGHTS': [10.0, 10.0, 5.0, 5.0],\n",
            "           'FG_RATIO': 0.25,\n",
            "           'FG_THRESH': 0.5},\n",
            " 'MODE_FPN': True,\n",
            " 'MODE_MASK': False,\n",
            " 'MRCNN': {'HEAD_DIM': 256},\n",
            " 'PREPROC': {'MAX_SIZE': 1344.0,\n",
            "             'PIXEL_MEAN': [123.675, 116.28, 103.53],\n",
            "             'PIXEL_STD': [58.395, 57.12, 57.375],\n",
            "             'TEST_SHORT_EDGE_SIZE': 600,\n",
            "             'TRAIN_SHORT_EDGE_SIZE': [600, 600]},\n",
            " 'RPN': {'ANCHOR_RATIOS': (0.5, 1.0, 2.0),\n",
            "         'ANCHOR_SIZES': (32, 64, 128, 256, 512),\n",
            "         'ANCHOR_STRIDE': 16,\n",
            "         'BATCH_PER_IM': 256,\n",
            "         'CROWD_OVERLAP_THRESH': 9.99,\n",
            "         'FG_RATIO': 0.5,\n",
            "         'HEAD_DIM': 1024,\n",
            "         'MIN_SIZE': 0,\n",
            "         'NEGATIVE_ANCHOR_THRESH': 0.3,\n",
            "         'NUM_ANCHOR': 15,\n",
            "         'POSITIVE_ANCHOR_THRESH': 0.7,\n",
            "         'PROPOSAL_NMS_THRESH': 0.7,\n",
            "         'TEST_PER_LEVEL_NMS_TOPK': 1000,\n",
            "         'TEST_POST_NMS_TOPK': 1000,\n",
            "         'TEST_PRE_NMS_TOPK': 6000,\n",
            "         'TRAIN_PER_LEVEL_NMS_TOPK': 2000,\n",
            "         'TRAIN_POST_NMS_TOPK': 2000,\n",
            "         'TRAIN_PRE_NMS_TOPK': 12000},\n",
            " 'TEST': {'FRCNN_NMS_THRESH': 0.5,\n",
            "          'RESULTS_PER_IM': 100,\n",
            "          'RESULT_SCORE_THRESH': 0.05,\n",
            "          'RESULT_SCORE_THRESH_VIS': 0.3},\n",
            " 'TRAIN': {'BASE_LR': 0.01,\n",
            "           'EVAL_PERIOD': 25,\n",
            "           'LR_SCHEDULE': [5000, 6000, 7000],\n",
            "           'NUM_GPUS': 1,\n",
            "           'STARTING_EPOCH': 1,\n",
            "           'STEPS_PER_EPOCH': 500,\n",
            "           'WARMUP': 1000,\n",
            "           'WARMUP_INIT_LR': 0.0033000000000000004,\n",
            "           'WEIGHT_DECAY': 0.0001},\n",
            " 'TRAINER': 'replicated'}\n",
            "\u001b[32m[1107 08:03:32 @train.py:500]\u001b[0m Warm Up Schedule (steps, value): [(0, 0.0033000000000000004), (1000, 0.01)]\n",
            "\u001b[32m[1107 08:03:32 @train.py:501]\u001b[0m LR Schedule (epochs, value): [(2, 0.01), (80.0, 0.001), (96.0, 0.00010000000000000002)]\n",
            "loading annotations into memory...\n",
            "Done (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[1107 08:03:34 @dataset.py:45]\u001b[0m Instances loaded from ../data/annotations/instances_train_B1_1000h.json.\n",
            "100% 278/278 [00:07<00:00, 37.99it/s]\n",
            "\u001b[32m[1107 08:03:41 @timer.py:49]\u001b[0m Load Groundtruth Boxes for train_B1_1000h finished, time:7.3197 sec.\n",
            "\u001b[32m[1107 08:03:41 @data.py:49]\u001b[0m Ground-Truth Boxes:\n",
            "\u001b[36m| class   |   #box |\n",
            "|:--------|-------:|\n",
            "| BG      |      0 |\n",
            "| BG      |    150 |\n",
            "| BG      |    265 |\n",
            "| 1       |  19123 |\n",
            "| 2       |      0 |\n",
            "| 3       |      0 |\n",
            "| total   |  19538 |\u001b[0m\n",
            "\u001b[32m[1107 08:03:41 @data.py:294]\u001b[0m Filtered 0 images which contain no non-crowd groudtruth boxes. Total #images for training: 278\n",
            "\u001b[32m[1107 08:03:41 @sessinit.py:294]\u001b[0m Loading dictionary from /tmp/ImageNet-R50-AlignPadding.npz ...\n",
            "WARNING:tensorflow:From train.py:203: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "\u001b[32m[1107 08:03:42 @input_source.py:222]\u001b[0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...\n",
            "\u001b[32m[1107 08:03:42 @training.py:109]\u001b[0m Building graph for training tower 0 on device /gpu:0 ...\n",
            "WARNING:tensorflow:From /content/drive/My Drive/skasdc1/claran/basemodel.py:197: The name tf.ceil is deprecated. Please use tf.math.ceil instead.\n",
            "\n",
            "\u001b[32m[1107 08:03:42 @argtools.py:146]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Some BatchNorm layer uses moving_mean/moving_variance in training.\n",
            "\u001b[32m[1107 08:03:42 @registry.py:90]\u001b[0m 'conv0': [1, 3, ?, ?] --> [1, 64, ?, ?]\n",
            "\u001b[32m[1107 08:03:42 @registry.py:90]\u001b[0m 'pool0': [1, 64, ?, ?] --> [1, 64, ?, ?]\n",
            "WARNING:tensorflow:From /content/drive/My Drive/skasdc1/claran/basemodel.py:161: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "\u001b[32m[1107 08:03:42 @registry.py:90]\u001b[0m 'group0/block0/conv1': [1, 64, ?, ?] --> [1, 64, ?, ?]\n",
            "\u001b[32m[1107 08:03:42 @registry.py:90]\u001b[0m 'group0/block0/conv2': [1, 64, ?, ?] --> [1, 64, ?, ?]\n",
            "\u001b[32m[1107 08:03:42 @registry.py:90]\u001b[0m 'group0/block0/conv3': [1, 64, ?, ?] --> [1, 256, ?, ?]\n",
            "\u001b[32m[1107 08:03:42 @registry.py:90]\u001b[0m 'group0/block0/convshortcut': [1, 64, ?, ?] --> [1, 256, ?, ?]\n",
            "\u001b[32m[1107 08:03:42 @registry.py:90]\u001b[0m 'group0/block1/conv1': [1, 256, ?, ?] --> [1, 64, ?, ?]\n",
            "\u001b[32m[1107 08:03:42 @registry.py:90]\u001b[0m 'group0/block1/conv2': [1, 64, ?, ?] --> [1, 64, ?, ?]\n",
            "\u001b[32m[1107 08:03:42 @registry.py:90]\u001b[0m 'group0/block1/conv3': [1, 64, ?, ?] --> [1, 256, ?, ?]\n",
            "\u001b[32m[1107 08:03:42 @registry.py:90]\u001b[0m 'group0/block2/conv1': [1, 256, ?, ?] --> [1, 64, ?, ?]\n",
            "\u001b[32m[1107 08:03:42 @registry.py:90]\u001b[0m 'group0/block2/conv2': [1, 64, ?, ?] --> [1, 64, ?, ?]\n",
            "\u001b[32m[1107 08:03:42 @registry.py:90]\u001b[0m 'group0/block2/conv3': [1, 64, ?, ?] --> [1, 256, ?, ?]\n",
            "\u001b[32m[1107 08:03:42 @registry.py:90]\u001b[0m 'group1/block0/conv1': [1, 256, ?, ?] --> [1, 128, ?, ?]\n",
            "\u001b[32m[1107 08:03:43 @registry.py:90]\u001b[0m 'group1/block0/conv2': [1, 128, ?, ?] --> [1, 128, ?, ?]\n",
            "\u001b[32m[1107 08:03:43 @registry.py:90]\u001b[0m 'group1/block0/conv3': [1, 128, ?, ?] --> [1, 512, ?, ?]\n",
            "\u001b[32m[1107 08:03:43 @registry.py:90]\u001b[0m 'group1/block0/convshortcut': [1, 256, ?, ?] --> [1, 512, ?, ?]\n",
            "\u001b[32m[1107 08:03:43 @registry.py:90]\u001b[0m 'group1/block1/conv1': [1, 512, ?, ?] --> [1, 128, ?, ?]\n",
            "\u001b[32m[1107 08:03:43 @registry.py:90]\u001b[0m 'group1/block1/conv2': [1, 128, ?, ?] --> [1, 128, ?, ?]\n",
            "\u001b[32m[1107 08:03:43 @registry.py:90]\u001b[0m 'group1/block1/conv3': [1, 128, ?, ?] --> [1, 512, ?, ?]\n",
            "\u001b[32m[1107 08:03:43 @registry.py:90]\u001b[0m 'group1/block2/conv1': [1, 512, ?, ?] --> [1, 128, ?, ?]\n",
            "\u001b[32m[1107 08:03:43 @registry.py:90]\u001b[0m 'group1/block2/conv2': [1, 128, ?, ?] --> [1, 128, ?, ?]\n",
            "\u001b[32m[1107 08:03:43 @registry.py:90]\u001b[0m 'group1/block2/conv3': [1, 128, ?, ?] --> [1, 512, ?, ?]\n",
            "\u001b[32m[1107 08:03:43 @registry.py:90]\u001b[0m 'group1/block3/conv1': [1, 512, ?, ?] --> [1, 128, ?, ?]\n",
            "\u001b[32m[1107 08:03:43 @registry.py:90]\u001b[0m 'group1/block3/conv2': [1, 128, ?, ?] --> [1, 128, ?, ?]\n",
            "\u001b[32m[1107 08:03:43 @registry.py:90]\u001b[0m 'group1/block3/conv3': [1, 128, ?, ?] --> [1, 512, ?, ?]\n",
            "\u001b[32m[1107 08:03:43 @registry.py:90]\u001b[0m 'group2/block0/conv1': [1, 512, ?, ?] --> [1, 256, ?, ?]\n",
            "\u001b[32m[1107 08:03:43 @registry.py:90]\u001b[0m 'group2/block0/conv2': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
            "\u001b[32m[1107 08:03:43 @registry.py:90]\u001b[0m 'group2/block0/conv3': [1, 256, ?, ?] --> [1, 1024, ?, ?]\n",
            "\u001b[32m[1107 08:03:43 @registry.py:90]\u001b[0m 'group2/block0/convshortcut': [1, 512, ?, ?] --> [1, 1024, ?, ?]\n",
            "\u001b[32m[1107 08:03:43 @registry.py:90]\u001b[0m 'group2/block1/conv1': [1, 1024, ?, ?] --> [1, 256, ?, ?]\n",
            "\u001b[32m[1107 08:03:43 @registry.py:90]\u001b[0m 'group2/block1/conv2': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
            "\u001b[32m[1107 08:03:43 @registry.py:90]\u001b[0m 'group2/block1/conv3': [1, 256, ?, ?] --> [1, 1024, ?, ?]\n",
            "\u001b[32m[1107 08:03:43 @registry.py:90]\u001b[0m 'group2/block2/conv1': [1, 1024, ?, ?] --> [1, 256, ?, ?]\n",
            "\u001b[32m[1107 08:03:43 @registry.py:90]\u001b[0m 'group2/block2/conv2': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
            "\u001b[32m[1107 08:03:43 @registry.py:90]\u001b[0m 'group2/block2/conv3': [1, 256, ?, ?] --> [1, 1024, ?, ?]\n",
            "\u001b[32m[1107 08:03:43 @registry.py:90]\u001b[0m 'group2/block3/conv1': [1, 1024, ?, ?] --> [1, 256, ?, ?]\n",
            "\u001b[32m[1107 08:03:43 @registry.py:90]\u001b[0m 'group2/block3/conv2': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
            "\u001b[32m[1107 08:03:43 @registry.py:90]\u001b[0m 'group2/block3/conv3': [1, 256, ?, ?] --> [1, 1024, ?, ?]\n",
            "\u001b[32m[1107 08:03:44 @registry.py:90]\u001b[0m 'group2/block4/conv1': [1, 1024, ?, ?] --> [1, 256, ?, ?]\n",
            "\u001b[32m[1107 08:03:44 @registry.py:90]\u001b[0m 'group2/block4/conv2': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
            "\u001b[32m[1107 08:03:44 @registry.py:90]\u001b[0m 'group2/block4/conv3': [1, 256, ?, ?] --> [1, 1024, ?, ?]\n",
            "\u001b[32m[1107 08:03:44 @registry.py:90]\u001b[0m 'group2/block5/conv1': [1, 1024, ?, ?] --> [1, 256, ?, ?]\n",
            "\u001b[32m[1107 08:03:44 @registry.py:90]\u001b[0m 'group2/block5/conv2': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
            "\u001b[32m[1107 08:03:44 @registry.py:90]\u001b[0m 'group2/block5/conv3': [1, 256, ?, ?] --> [1, 1024, ?, ?]\n",
            "\u001b[32m[1107 08:03:44 @registry.py:90]\u001b[0m 'group3/block0/conv1': [1, 1024, ?, ?] --> [1, 512, ?, ?]\n",
            "\u001b[32m[1107 08:03:44 @registry.py:90]\u001b[0m 'group3/block0/conv2': [1, 512, ?, ?] --> [1, 512, ?, ?]\n",
            "\u001b[32m[1107 08:03:44 @registry.py:90]\u001b[0m 'group3/block0/conv3': [1, 512, ?, ?] --> [1, 2048, ?, ?]\n",
            "\u001b[32m[1107 08:03:44 @registry.py:90]\u001b[0m 'group3/block0/convshortcut': [1, 1024, ?, ?] --> [1, 2048, ?, ?]\n",
            "\u001b[32m[1107 08:03:44 @registry.py:90]\u001b[0m 'group3/block1/conv1': [1, 2048, ?, ?] --> [1, 512, ?, ?]\n",
            "\u001b[32m[1107 08:03:44 @registry.py:90]\u001b[0m 'group3/block1/conv2': [1, 512, ?, ?] --> [1, 512, ?, ?]\n",
            "\u001b[32m[1107 08:03:44 @registry.py:90]\u001b[0m 'group3/block1/conv3': [1, 512, ?, ?] --> [1, 2048, ?, ?]\n",
            "\u001b[32m[1107 08:03:44 @registry.py:90]\u001b[0m 'group3/block2/conv1': [1, 2048, ?, ?] --> [1, 512, ?, ?]\n",
            "\u001b[32m[1107 08:03:44 @registry.py:90]\u001b[0m 'group3/block2/conv2': [1, 512, ?, ?] --> [1, 512, ?, ?]\n",
            "\u001b[32m[1107 08:03:44 @registry.py:90]\u001b[0m 'group3/block2/conv3': [1, 512, ?, ?] --> [1, 2048, ?, ?]\n",
            "\u001b[32m[1107 08:03:44 @registry.py:80]\u001b[0m 'fpn' input: [1, 256, ?, ?], [1, 512, ?, ?], [1, 1024, ?, ?], [1, 2048, ?, ?]\n",
            "\u001b[32m[1107 08:03:44 @registry.py:90]\u001b[0m   'fpn/lateral_1x1_c2': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
            "\u001b[32m[1107 08:03:44 @registry.py:90]\u001b[0m   'fpn/lateral_1x1_c3': [1, 512, ?, ?] --> [1, 256, ?, ?]\n",
            "\u001b[32m[1107 08:03:44 @registry.py:90]\u001b[0m   'fpn/lateral_1x1_c4': [1, 1024, ?, ?] --> [1, 256, ?, ?]\n",
            "\u001b[32m[1107 08:03:44 @registry.py:90]\u001b[0m   'fpn/lateral_1x1_c5': [1, 2048, ?, ?] --> [1, 256, ?, ?]\n",
            "\u001b[32m[1107 08:03:44 @registry.py:90]\u001b[0m   'fpn/upsample_lat5': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
            "\u001b[32m[1107 08:03:44 @registry.py:90]\u001b[0m   'fpn/upsample_lat4': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
            "\u001b[32m[1107 08:03:44 @registry.py:90]\u001b[0m   'fpn/upsample_lat3': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
            "\u001b[32m[1107 08:03:44 @registry.py:90]\u001b[0m   'fpn/posthoc_3x3_p2': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
            "\u001b[32m[1107 08:03:44 @registry.py:90]\u001b[0m   'fpn/posthoc_3x3_p3': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
            "\u001b[32m[1107 08:03:44 @registry.py:90]\u001b[0m   'fpn/posthoc_3x3_p4': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
            "\u001b[32m[1107 08:03:44 @registry.py:90]\u001b[0m   'fpn/posthoc_3x3_p5': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
            "\u001b[32m[1107 08:03:44 @registry.py:90]\u001b[0m   'fpn/maxpool_p6': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
            "\u001b[32m[1107 08:03:44 @registry.py:93]\u001b[0m 'fpn' output: [1, 256, ?, ?], [1, 256, ?, ?], [1, 256, ?, ?], [1, 256, ?, ?], [1, 256, ?, ?]\n",
            "\u001b[32m[1107 08:03:45 @registry.py:80]\u001b[0m 'rpn' input: [1, 256, ?, ?]\n",
            "\u001b[32m[1107 08:03:45 @registry.py:90]\u001b[0m   'rpn/conv0': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
            "\u001b[32m[1107 08:03:45 @registry.py:90]\u001b[0m   'rpn/class': [1, 256, ?, ?] --> [1, 3, ?, ?]\n",
            "\u001b[32m[1107 08:03:45 @registry.py:90]\u001b[0m   'rpn/box': [1, 256, ?, ?] --> [1, 12, ?, ?]\n",
            "\u001b[32m[1107 08:03:45 @registry.py:93]\u001b[0m 'rpn' output: [?, ?, 3], [?, ?, 3, 4]\n",
            "WARNING:tensorflow:From /content/drive/My Drive/skasdc1/claran/model_box.py:77: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/skasdc1/claran/model_rpn.py:93: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/skasdc1/claran/model_rpn.py:95: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/skasdc1/claran/model_frcnn.py:74: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/skasdc1/claran/model_box.py:172: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/skasdc1/claran/model_fpn.py:128: The name tf.invert_permutation is deprecated. Please use tf.math.invert_permutation instead.\n",
            "\n",
            "\u001b[32m[1107 08:03:47 @registry.py:80]\u001b[0m 'fastrcnn' input: [?, 256, 7, 7]\n",
            "\u001b[32m[1107 08:03:47 @registry.py:90]\u001b[0m   'fastrcnn/fc6': [?, 256, 7, 7] --> [?, 1024]\n",
            "\u001b[32m[1107 08:03:47 @registry.py:90]\u001b[0m   'fastrcnn/fc7': [?, 1024] --> [?, 1024]\n",
            "\u001b[32m[1107 08:03:47 @registry.py:93]\u001b[0m 'fastrcnn' output: [?, 1024]\n",
            "\u001b[32m[1107 08:03:47 @registry.py:80]\u001b[0m 'fastrcnn/outputs' input: [?, 1024]\n",
            "\u001b[32m[1107 08:03:48 @registry.py:90]\u001b[0m   'fastrcnn/outputs/class': [?, 1024] --> [?, 4]\n",
            "\u001b[32m[1107 08:03:48 @registry.py:90]\u001b[0m   'fastrcnn/outputs/box': [?, 1024] --> [?, 16]\n",
            "\u001b[32m[1107 08:03:48 @registry.py:93]\u001b[0m 'fastrcnn/outputs' output: [?, 4], [?, 4, 4]\n",
            "\u001b[32m[1107 08:03:48 @regularize.py:97]\u001b[0m regularize_cost() found 57 variables to regularize.\n",
            "\u001b[32m[1107 08:03:48 @regularize.py:21]\u001b[0m The following tensors will be regularized: group1/block0/conv1/W:0, group1/block0/conv2/W:0, group1/block0/conv3/W:0, group1/block0/convshortcut/W:0, group1/block1/conv1/W:0, group1/block1/conv2/W:0, group1/block1/conv3/W:0, group1/block2/conv1/W:0, group1/block2/conv2/W:0, group1/block2/conv3/W:0, group1/block3/conv1/W:0, group1/block3/conv2/W:0, group1/block3/conv3/W:0, group2/block0/conv1/W:0, group2/block0/conv2/W:0, group2/block0/conv3/W:0, group2/block0/convshortcut/W:0, group2/block1/conv1/W:0, group2/block1/conv2/W:0, group2/block1/conv3/W:0, group2/block2/conv1/W:0, group2/block2/conv2/W:0, group2/block2/conv3/W:0, group2/block3/conv1/W:0, group2/block3/conv2/W:0, group2/block3/conv3/W:0, group2/block4/conv1/W:0, group2/block4/conv2/W:0, group2/block4/conv3/W:0, group2/block5/conv1/W:0, group2/block5/conv2/W:0, group2/block5/conv3/W:0, group3/block0/conv1/W:0, group3/block0/conv2/W:0, group3/block0/conv3/W:0, group3/block0/convshortcut/W:0, group3/block1/conv1/W:0, group3/block1/conv2/W:0, group3/block1/conv3/W:0, group3/block2/conv1/W:0, group3/block2/conv2/W:0, group3/block2/conv3/W:0, fpn/lateral_1x1_c2/W:0, fpn/lateral_1x1_c3/W:0, fpn/lateral_1x1_c4/W:0, fpn/lateral_1x1_c5/W:0, fpn/posthoc_3x3_p2/W:0, fpn/posthoc_3x3_p3/W:0, fpn/posthoc_3x3_p4/W:0, fpn/posthoc_3x3_p5/W:0, rpn/conv0/W:0, rpn/class/W:0, rpn/box/W:0, fastrcnn/fc6/W:0, fastrcnn/fc7/W:0, fastrcnn/outputs/class/W:0, fastrcnn/outputs/box/W:0\n",
            "WARNING:tensorflow:From train.py:55: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From train.py:56: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From train.py:60: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorpack/tfutils/optimizer.py:201: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorpack/tfutils/optimizer.py:210: The name tf.mod is deprecated. Please use tf.math.mod instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorpack/tfutils/optimizer.py:207: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "\u001b[32m[1107 08:03:54 @model_utils.py:67]\u001b[0m \u001b[36mList of Trainable Variables: \n",
            "\u001b[0mname                                 shape                 #elements\n",
            "-----------------------------------  ------------------  -----------\n",
            "group1/block0/conv1/W                [1, 1, 256, 128]          32768\n",
            "group1/block0/conv1/bn/gamma         [128]                       128\n",
            "group1/block0/conv1/bn/beta          [128]                       128\n",
            "group1/block0/conv2/W                [3, 3, 128, 128]         147456\n",
            "group1/block0/conv2/bn/gamma         [128]                       128\n",
            "group1/block0/conv2/bn/beta          [128]                       128\n",
            "group1/block0/conv3/W                [1, 1, 128, 512]          65536\n",
            "group1/block0/conv3/bn/gamma         [512]                       512\n",
            "group1/block0/conv3/bn/beta          [512]                       512\n",
            "group1/block0/convshortcut/W         [1, 1, 256, 512]         131072\n",
            "group1/block0/convshortcut/bn/gamma  [512]                       512\n",
            "group1/block0/convshortcut/bn/beta   [512]                       512\n",
            "group1/block1/conv1/W                [1, 1, 512, 128]          65536\n",
            "group1/block1/conv1/bn/gamma         [128]                       128\n",
            "group1/block1/conv1/bn/beta          [128]                       128\n",
            "group1/block1/conv2/W                [3, 3, 128, 128]         147456\n",
            "group1/block1/conv2/bn/gamma         [128]                       128\n",
            "group1/block1/conv2/bn/beta          [128]                       128\n",
            "group1/block1/conv3/W                [1, 1, 128, 512]          65536\n",
            "group1/block1/conv3/bn/gamma         [512]                       512\n",
            "group1/block1/conv3/bn/beta          [512]                       512\n",
            "group1/block2/conv1/W                [1, 1, 512, 128]          65536\n",
            "group1/block2/conv1/bn/gamma         [128]                       128\n",
            "group1/block2/conv1/bn/beta          [128]                       128\n",
            "group1/block2/conv2/W                [3, 3, 128, 128]         147456\n",
            "group1/block2/conv2/bn/gamma         [128]                       128\n",
            "group1/block2/conv2/bn/beta          [128]                       128\n",
            "group1/block2/conv3/W                [1, 1, 128, 512]          65536\n",
            "group1/block2/conv3/bn/gamma         [512]                       512\n",
            "group1/block2/conv3/bn/beta          [512]                       512\n",
            "group1/block3/conv1/W                [1, 1, 512, 128]          65536\n",
            "group1/block3/conv1/bn/gamma         [128]                       128\n",
            "group1/block3/conv1/bn/beta          [128]                       128\n",
            "group1/block3/conv2/W                [3, 3, 128, 128]         147456\n",
            "group1/block3/conv2/bn/gamma         [128]                       128\n",
            "group1/block3/conv2/bn/beta          [128]                       128\n",
            "group1/block3/conv3/W                [1, 1, 128, 512]          65536\n",
            "group1/block3/conv3/bn/gamma         [512]                       512\n",
            "group1/block3/conv3/bn/beta          [512]                       512\n",
            "group2/block0/conv1/W                [1, 1, 512, 256]         131072\n",
            "group2/block0/conv1/bn/gamma         [256]                       256\n",
            "group2/block0/conv1/bn/beta          [256]                       256\n",
            "group2/block0/conv2/W                [3, 3, 256, 256]         589824\n",
            "group2/block0/conv2/bn/gamma         [256]                       256\n",
            "group2/block0/conv2/bn/beta          [256]                       256\n",
            "group2/block0/conv3/W                [1, 1, 256, 1024]        262144\n",
            "group2/block0/conv3/bn/gamma         [1024]                     1024\n",
            "group2/block0/conv3/bn/beta          [1024]                     1024\n",
            "group2/block0/convshortcut/W         [1, 1, 512, 1024]        524288\n",
            "group2/block0/convshortcut/bn/gamma  [1024]                     1024\n",
            "group2/block0/convshortcut/bn/beta   [1024]                     1024\n",
            "group2/block1/conv1/W                [1, 1, 1024, 256]        262144\n",
            "group2/block1/conv1/bn/gamma         [256]                       256\n",
            "group2/block1/conv1/bn/beta          [256]                       256\n",
            "group2/block1/conv2/W                [3, 3, 256, 256]         589824\n",
            "group2/block1/conv2/bn/gamma         [256]                       256\n",
            "group2/block1/conv2/bn/beta          [256]                       256\n",
            "group2/block1/conv3/W                [1, 1, 256, 1024]        262144\n",
            "group2/block1/conv3/bn/gamma         [1024]                     1024\n",
            "group2/block1/conv3/bn/beta          [1024]                     1024\n",
            "group2/block2/conv1/W                [1, 1, 1024, 256]        262144\n",
            "group2/block2/conv1/bn/gamma         [256]                       256\n",
            "group2/block2/conv1/bn/beta          [256]                       256\n",
            "group2/block2/conv2/W                [3, 3, 256, 256]         589824\n",
            "group2/block2/conv2/bn/gamma         [256]                       256\n",
            "group2/block2/conv2/bn/beta          [256]                       256\n",
            "group2/block2/conv3/W                [1, 1, 256, 1024]        262144\n",
            "group2/block2/conv3/bn/gamma         [1024]                     1024\n",
            "group2/block2/conv3/bn/beta          [1024]                     1024\n",
            "group2/block3/conv1/W                [1, 1, 1024, 256]        262144\n",
            "group2/block3/conv1/bn/gamma         [256]                       256\n",
            "group2/block3/conv1/bn/beta          [256]                       256\n",
            "group2/block3/conv2/W                [3, 3, 256, 256]         589824\n",
            "group2/block3/conv2/bn/gamma         [256]                       256\n",
            "group2/block3/conv2/bn/beta          [256]                       256\n",
            "group2/block3/conv3/W                [1, 1, 256, 1024]        262144\n",
            "group2/block3/conv3/bn/gamma         [1024]                     1024\n",
            "group2/block3/conv3/bn/beta          [1024]                     1024\n",
            "group2/block4/conv1/W                [1, 1, 1024, 256]        262144\n",
            "group2/block4/conv1/bn/gamma         [256]                       256\n",
            "group2/block4/conv1/bn/beta          [256]                       256\n",
            "group2/block4/conv2/W                [3, 3, 256, 256]         589824\n",
            "group2/block4/conv2/bn/gamma         [256]                       256\n",
            "group2/block4/conv2/bn/beta          [256]                       256\n",
            "group2/block4/conv3/W                [1, 1, 256, 1024]        262144\n",
            "group2/block4/conv3/bn/gamma         [1024]                     1024\n",
            "group2/block4/conv3/bn/beta          [1024]                     1024\n",
            "group2/block5/conv1/W                [1, 1, 1024, 256]        262144\n",
            "group2/block5/conv1/bn/gamma         [256]                       256\n",
            "group2/block5/conv1/bn/beta          [256]                       256\n",
            "group2/block5/conv2/W                [3, 3, 256, 256]         589824\n",
            "group2/block5/conv2/bn/gamma         [256]                       256\n",
            "group2/block5/conv2/bn/beta          [256]                       256\n",
            "group2/block5/conv3/W                [1, 1, 256, 1024]        262144\n",
            "group2/block5/conv3/bn/gamma         [1024]                     1024\n",
            "group2/block5/conv3/bn/beta          [1024]                     1024\n",
            "group3/block0/conv1/W                [1, 1, 1024, 512]        524288\n",
            "group3/block0/conv1/bn/gamma         [512]                       512\n",
            "group3/block0/conv1/bn/beta          [512]                       512\n",
            "group3/block0/conv2/W                [3, 3, 512, 512]        2359296\n",
            "group3/block0/conv2/bn/gamma         [512]                       512\n",
            "group3/block0/conv2/bn/beta          [512]                       512\n",
            "group3/block0/conv3/W                [1, 1, 512, 2048]       1048576\n",
            "group3/block0/conv3/bn/gamma         [2048]                     2048\n",
            "group3/block0/conv3/bn/beta          [2048]                     2048\n",
            "group3/block0/convshortcut/W         [1, 1, 1024, 2048]      2097152\n",
            "group3/block0/convshortcut/bn/gamma  [2048]                     2048\n",
            "group3/block0/convshortcut/bn/beta   [2048]                     2048\n",
            "group3/block1/conv1/W                [1, 1, 2048, 512]       1048576\n",
            "group3/block1/conv1/bn/gamma         [512]                       512\n",
            "group3/block1/conv1/bn/beta          [512]                       512\n",
            "group3/block1/conv2/W                [3, 3, 512, 512]        2359296\n",
            "group3/block1/conv2/bn/gamma         [512]                       512\n",
            "group3/block1/conv2/bn/beta          [512]                       512\n",
            "group3/block1/conv3/W                [1, 1, 512, 2048]       1048576\n",
            "group3/block1/conv3/bn/gamma         [2048]                     2048\n",
            "group3/block1/conv3/bn/beta          [2048]                     2048\n",
            "group3/block2/conv1/W                [1, 1, 2048, 512]       1048576\n",
            "group3/block2/conv1/bn/gamma         [512]                       512\n",
            "group3/block2/conv1/bn/beta          [512]                       512\n",
            "group3/block2/conv2/W                [3, 3, 512, 512]        2359296\n",
            "group3/block2/conv2/bn/gamma         [512]                       512\n",
            "group3/block2/conv2/bn/beta          [512]                       512\n",
            "group3/block2/conv3/W                [1, 1, 512, 2048]       1048576\n",
            "group3/block2/conv3/bn/gamma         [2048]                     2048\n",
            "group3/block2/conv3/bn/beta          [2048]                     2048\n",
            "fpn/lateral_1x1_c2/W                 [1, 1, 256, 256]          65536\n",
            "fpn/lateral_1x1_c2/b                 [256]                       256\n",
            "fpn/lateral_1x1_c3/W                 [1, 1, 512, 256]         131072\n",
            "fpn/lateral_1x1_c3/b                 [256]                       256\n",
            "fpn/lateral_1x1_c4/W                 [1, 1, 1024, 256]        262144\n",
            "fpn/lateral_1x1_c4/b                 [256]                       256\n",
            "fpn/lateral_1x1_c5/W                 [1, 1, 2048, 256]        524288\n",
            "fpn/lateral_1x1_c5/b                 [256]                       256\n",
            "fpn/posthoc_3x3_p2/W                 [3, 3, 256, 256]         589824\n",
            "fpn/posthoc_3x3_p2/b                 [256]                       256\n",
            "fpn/posthoc_3x3_p3/W                 [3, 3, 256, 256]         589824\n",
            "fpn/posthoc_3x3_p3/b                 [256]                       256\n",
            "fpn/posthoc_3x3_p4/W                 [3, 3, 256, 256]         589824\n",
            "fpn/posthoc_3x3_p4/b                 [256]                       256\n",
            "fpn/posthoc_3x3_p5/W                 [3, 3, 256, 256]         589824\n",
            "fpn/posthoc_3x3_p5/b                 [256]                       256\n",
            "rpn/conv0/W                          [3, 3, 256, 256]         589824\n",
            "rpn/conv0/b                          [256]                       256\n",
            "rpn/class/W                          [1, 1, 256, 3]              768\n",
            "rpn/class/b                          [3]                           3\n",
            "rpn/box/W                            [1, 1, 256, 12]            3072\n",
            "rpn/box/b                            [12]                         12\n",
            "fastrcnn/fc6/W                       [12544, 1024]          12845056\n",
            "fastrcnn/fc6/b                       [1024]                     1024\n",
            "fastrcnn/fc7/W                       [1024, 1024]            1048576\n",
            "fastrcnn/fc7/b                       [1024]                     1024\n",
            "fastrcnn/outputs/class/W             [1024, 4]                  4096\n",
            "fastrcnn/outputs/class/b             [4]                           4\n",
            "fastrcnn/outputs/box/W               [1024, 16]                16384\n",
            "fastrcnn/outputs/box/b               [16]                         16\u001b[36m\n",
            "Number of trainable variables: 156\n",
            "Number of parameters (elements): 41137187\n",
            "Storage space needed for all trainable variables: 156.93MB\u001b[0m\n",
            "\u001b[32m[1107 08:03:54 @base.py:209]\u001b[0m Setup callbacks graph ...\n",
            "\u001b[32m[1107 08:03:54 @argtools.py:146]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Starting a process with 'fork' method is not safe and may consume unnecessary extra CPU memory. Use 'forkserver' or 'spawn' method (available after Py3.4) instead if you run into any issues. See https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods on how to set them.\n",
            "\u001b[32m[1107 08:03:54 @argtools.py:146]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m \"import prctl\" failed! Install python-prctl so that processes can be cleaned with guarantee.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorpack/callbacks/prof.py:262: The name tf.train.SessionRunArgs is deprecated. Please use tf.estimator.SessionRunArgs instead.\n",
            "\n",
            "\u001b[32m[1107 08:04:04 @tower.py:140]\u001b[0m Building graph for predict tower 'tower-pred-0' on device /gpu:0 ...\n",
            "\u001b[32m[1107 08:04:06 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_return_params [train.py:547] will be deprecated after 06 Jun. Please use `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:06 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_return_params [train.py:547] will be deprecated after 06 Jun. Please use `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:06 @argtools.py:146]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The old augmentor interface was deprecated. Please implement CustomResize with `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:06 @argtools.py:146]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The old augmentor interface was deprecated. Please implement CustomResize with `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:06 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_return_params [train.py:547] will be deprecated after 06 Jun. Please use `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:06 @argtools.py:146]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The old augmentor interface was deprecated. Please implement CustomResize with `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:06 @argtools.py:146]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The old augmentor interface was deprecated. Please implement RotateImg with `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:06 @argtools.py:146]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The old augmentor interface was deprecated. Please implement RotateImg with `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:06 @argtools.py:146]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The old augmentor interface was deprecated. Please implement RotateImg with `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:06 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_return_params [train.py:547] will be deprecated after 06 Jun. Please use `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:06 @argtools.py:146]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The old augmentor interface was deprecated. Please implement CustomResize with `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:06 @argtools.py:146]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The old augmentor interface was deprecated. Please implement RotateImg with `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:06 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_coords [train.py:547] will be deprecated after 06 Jun. Please use `transform.apply_coords` instead!\n",
            "\u001b[32m[1107 08:04:06 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_coords [train.py:547] will be deprecated after 06 Jun. Please use `transform.apply_coords` instead!\n",
            "\u001b[32m[1107 08:04:06 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_coords [train.py:547] will be deprecated after 06 Jun. Please use `transform.apply_coords` instead!\n",
            "\u001b[32m[1107 08:04:06 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_coords [train.py:547] will be deprecated after 06 Jun. Please use `transform.apply_coords` instead!\n",
            "\u001b[32m[1107 08:04:06 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_return_params [train.py:547] will be deprecated after 06 Jun. Please use `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:06 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_return_params [train.py:547] will be deprecated after 06 Jun. Please use `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:06 @argtools.py:146]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The old augmentor interface was deprecated. Please implement CustomResize with `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:06 @argtools.py:146]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The old augmentor interface was deprecated. Please implement CustomResize with `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:06 @argtools.py:146]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The old augmentor interface was deprecated. Please implement RotateImg with `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:06 @argtools.py:146]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The old augmentor interface was deprecated. Please implement RotateImg with `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:06 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_return_params [train.py:547] will be deprecated after 06 Jun. Please use `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:06 @argtools.py:146]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The old augmentor interface was deprecated. Please implement CustomResize with `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:06 @argtools.py:146]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The old augmentor interface was deprecated. Please implement RotateImg with `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:06 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_return_params [train.py:547] will be deprecated after 06 Jun. Please use `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:06 @argtools.py:146]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The old augmentor interface was deprecated. Please implement CustomResize with `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:06 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_return_params [train.py:547] will be deprecated after 06 Jun. Please use `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:06 @argtools.py:146]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The old augmentor interface was deprecated. Please implement CustomResize with `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:06 @argtools.py:146]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The old augmentor interface was deprecated. Please implement RotateImg with `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:06 @argtools.py:146]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The old augmentor interface was deprecated. Please implement RotateImg with `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:06 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_return_params [train.py:547] will be deprecated after 06 Jun. Please use `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:06 @argtools.py:146]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The old augmentor interface was deprecated. Please implement CustomResize with `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:06 @argtools.py:146]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The old augmentor interface was deprecated. Please implement RotateImg with `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:06 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_coords [train.py:547] will be deprecated after 06 Jun. Please use `transform.apply_coords` instead!\n",
            "\u001b[32m[1107 08:04:06 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_coords [train.py:547] will be deprecated after 06 Jun. Please use `transform.apply_coords` instead!\n",
            "\u001b[32m[1107 08:04:06 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_coords [train.py:547] will be deprecated after 06 Jun. Please use `transform.apply_coords` instead!\n",
            "\u001b[32m[1107 08:04:06 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_coords [train.py:547] will be deprecated after 06 Jun. Please use `transform.apply_coords` instead!\n",
            "\u001b[32m[1107 08:04:06 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_coords [train.py:547] will be deprecated after 06 Jun. Please use `transform.apply_coords` instead!\n",
            "\u001b[32m[1107 08:04:06 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_coords [train.py:547] will be deprecated after 06 Jun. Please use `transform.apply_coords` instead!\n",
            "\u001b[32m[1107 08:04:08 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_return_params [train.py:547] will be deprecated after 06 Jun. Please use `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:08 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_coords [train.py:547] will be deprecated after 06 Jun. Please use `transform.apply_coords` instead!\n",
            "\u001b[32m[1107 08:04:08 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_return_params [train.py:547] will be deprecated after 06 Jun. Please use `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:08 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_coords [train.py:547] will be deprecated after 06 Jun. Please use `transform.apply_coords` instead!\n",
            "\u001b[32m[1107 08:04:08 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_return_params [train.py:547] will be deprecated after 06 Jun. Please use `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:08 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_coords [train.py:547] will be deprecated after 06 Jun. Please use `transform.apply_coords` instead!\n",
            "\u001b[32m[1107 08:04:09 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_return_params [train.py:547] will be deprecated after 06 Jun. Please use `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:09 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_return_params [train.py:547] will be deprecated after 06 Jun. Please use `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:09 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_return_params [train.py:547] will be deprecated after 06 Jun. Please use `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:09 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_return_params [train.py:547] will be deprecated after 06 Jun. Please use `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:09 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_coords [train.py:547] will be deprecated after 06 Jun. Please use `transform.apply_coords` instead!\n",
            "\u001b[32m[1107 08:04:09 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_coords [train.py:547] will be deprecated after 06 Jun. Please use `transform.apply_coords` instead!\n",
            "\u001b[32m[1107 08:04:09 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_return_params [train.py:547] will be deprecated after 06 Jun. Please use `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:09 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_coords [train.py:547] will be deprecated after 06 Jun. Please use `transform.apply_coords` instead!\n",
            "\u001b[32m[1107 08:04:09 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_coords [train.py:547] will be deprecated after 06 Jun. Please use `transform.apply_coords` instead!\n",
            "\u001b[32m[1107 08:04:09 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_coords [train.py:547] will be deprecated after 06 Jun. Please use `transform.apply_coords` instead!\n",
            "\u001b[32m[1107 08:04:09 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_return_params [train.py:547] will be deprecated after 06 Jun. Please use `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:09 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_coords [train.py:547] will be deprecated after 06 Jun. Please use `transform.apply_coords` instead!\n",
            "\u001b[32m[1107 08:04:09 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_return_params [train.py:547] will be deprecated after 06 Jun. Please use `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:09 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_coords [train.py:547] will be deprecated after 06 Jun. Please use `transform.apply_coords` instead!\n",
            "\u001b[32m[1107 08:04:09 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_return_params [train.py:547] will be deprecated after 06 Jun. Please use `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:09 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_coords [train.py:547] will be deprecated after 06 Jun. Please use `transform.apply_coords` instead!\n",
            "\u001b[32m[1107 08:04:10 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_return_params [train.py:547] will be deprecated after 06 Jun. Please use `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:10 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_return_params [train.py:547] will be deprecated after 06 Jun. Please use `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:10 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_coords [train.py:547] will be deprecated after 06 Jun. Please use `transform.apply_coords` instead!\n",
            "\u001b[32m[1107 08:04:10 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_coords [train.py:547] will be deprecated after 06 Jun. Please use `transform.apply_coords` instead!\n",
            "\u001b[32m[1107 08:04:10 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_return_params [train.py:547] will be deprecated after 06 Jun. Please use `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:10 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_coords [train.py:547] will be deprecated after 06 Jun. Please use `transform.apply_coords` instead!\n",
            "\u001b[32m[1107 08:04:10 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_return_params [train.py:547] will be deprecated after 06 Jun. Please use `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:10 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_coords [train.py:547] will be deprecated after 06 Jun. Please use `transform.apply_coords` instead!\n",
            "\u001b[32m[1107 08:04:10 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_return_params [train.py:547] will be deprecated after 06 Jun. Please use `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:10 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_return_params [train.py:547] will be deprecated after 06 Jun. Please use `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:11 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_coords [train.py:547] will be deprecated after 06 Jun. Please use `transform.apply_coords` instead!\n",
            "\u001b[32m[1107 08:04:11 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_coords [train.py:547] will be deprecated after 06 Jun. Please use `transform.apply_coords` instead!\n",
            "\u001b[32m[1107 08:04:11 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_return_params [train.py:547] will be deprecated after 06 Jun. Please use `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:11 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_coords [train.py:547] will be deprecated after 06 Jun. Please use `transform.apply_coords` instead!\n",
            "\u001b[32m[1107 08:04:11 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_return_params [train.py:547] will be deprecated after 06 Jun. Please use `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:11 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_coords [train.py:547] will be deprecated after 06 Jun. Please use `transform.apply_coords` instead!\n",
            "\u001b[32m[1107 08:04:11 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_return_params [train.py:547] will be deprecated after 06 Jun. Please use `get_transform` instead!\n",
            "\u001b[32m[1107 08:04:11 @develop.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] augment_coords [train.py:547] will be deprecated after 06 Jun. Please use `transform.apply_coords` instead!\n",
            "\u001b[32m[1107 08:04:15 @collection.py:152]\u001b[0m Size of these collections were changed in tower-pred-0: (tf.GraphKeys.MODEL_VARIABLES: 183->238)\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[1107 08:04:16 @dataset.py:45]\u001b[0m Instances loaded from ../data/annotations/instances_val_B1_1000h.json.\n",
            "100% 10/10 [00:00<00:00, 31.12it/s]\n",
            "\u001b[32m[1107 08:04:16 @timer.py:49]\u001b[0m Load Groundtruth Boxes for val_B1_1000h finished, time:0.3288 sec.\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[1107 08:04:16 @dataset.py:45]\u001b[0m Instances loaded from ../data/annotations/instances_val_B1_1000h.json.\n",
            "100% 10/10 [00:00<00:00, 4361.80it/s]\n",
            "\u001b[32m[1107 08:04:16 @timer.py:49]\u001b[0m Load Groundtruth Boxes for val_B1_1000h finished, time:0.0057 sec.\n",
            "\u001b[32m[1107 08:04:17 @summary.py:47]\u001b[0m [MovingAverageSummary] 69 operations in collection 'MOVING_SUMMARY_OPS' will be run with session hooks.\n",
            "\u001b[32m[1107 08:04:17 @summary.py:94]\u001b[0m Summarizing collection 'summaries' of size 71.\n",
            "\u001b[32m[1107 08:04:17 @base.py:230]\u001b[0m Creating the session ...\n",
            "2019-11-07 08:04:17.325988: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-11-07 08:04:17.326231: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1235a540 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2019-11-07 08:04:17.326275: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2019-11-07 08:04:17.333487: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2019-11-07 08:04:17.922144: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-07 08:04:17.923216: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1235a700 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2019-11-07 08:04:17.923256: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-11-07 08:04:17.924694: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-07 08:04:17.925494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-11-07 08:04:17.942630: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-11-07 08:04:18.166492: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-11-07 08:04:18.255219: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-11-07 08:04:18.280628: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-11-07 08:04:18.505433: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-11-07 08:04:18.648083: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-11-07 08:04:19.127809: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-11-07 08:04:19.128126: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-07 08:04:19.129137: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-07 08:04:19.129991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-11-07 08:04:19.134423: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-11-07 08:04:19.136635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-11-07 08:04:19.136681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2019-11-07 08:04:19.136706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2019-11-07 08:04:19.138052: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-07 08:04:19.139126: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-07 08:04:19.140051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11326 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "\u001b[32m[1107 08:04:44 @base.py:236]\u001b[0m Initializing the session ...\n",
            "\u001b[32m[1107 08:04:44 @sessinit.py:223]\u001b[0m Variables to restore from dict: conv0/W, conv0/bn/gamma, conv0/bn/beta, conv0/bn/mean/EMA, conv0/bn/variance/EMA, group0/block0/conv1/W, group0/block0/conv1/bn/gamma, group0/block0/conv1/bn/beta, group0/block0/conv1/bn/mean/EMA, group0/block0/conv1/bn/variance/EMA, group0/block0/conv2/W, group0/block0/conv2/bn/gamma, group0/block0/conv2/bn/beta, group0/block0/conv2/bn/mean/EMA, group0/block0/conv2/bn/variance/EMA, group0/block0/conv3/W, group0/block0/conv3/bn/gamma, group0/block0/conv3/bn/beta, group0/block0/conv3/bn/mean/EMA, group0/block0/conv3/bn/variance/EMA, group0/block0/convshortcut/W, group0/block0/convshortcut/bn/gamma, group0/block0/convshortcut/bn/beta, group0/block0/convshortcut/bn/mean/EMA, group0/block0/convshortcut/bn/variance/EMA, group0/block1/conv1/W, group0/block1/conv1/bn/gamma, group0/block1/conv1/bn/beta, group0/block1/conv1/bn/mean/EMA, group0/block1/conv1/bn/variance/EMA, group0/block1/conv2/W, group0/block1/conv2/bn/gamma, group0/block1/conv2/bn/beta, group0/block1/conv2/bn/mean/EMA, group0/block1/conv2/bn/variance/EMA, group0/block1/conv3/W, group0/block1/conv3/bn/gamma, group0/block1/conv3/bn/beta, group0/block1/conv3/bn/mean/EMA, group0/block1/conv3/bn/variance/EMA, group0/block2/conv1/W, group0/block2/conv1/bn/gamma, group0/block2/conv1/bn/beta, group0/block2/conv1/bn/mean/EMA, group0/block2/conv1/bn/variance/EMA, group0/block2/conv2/W, group0/block2/conv2/bn/gamma, group0/block2/conv2/bn/beta, group0/block2/conv2/bn/mean/EMA, group0/block2/conv2/bn/variance/EMA, group0/block2/conv3/W, group0/block2/conv3/bn/gamma, group0/block2/conv3/bn/beta, group0/block2/conv3/bn/mean/EMA, group0/block2/conv3/bn/variance/EMA, group1/block0/conv1/W, group1/block0/conv1/bn/gamma, group1/block0/conv1/bn/beta, group1/block0/conv1/bn/mean/EMA, group1/block0/conv1/bn/variance/EMA, group1/block0/conv2/W, group1/block0/conv2/bn/gamma, group1/block0/conv2/bn/beta, group1/block0/conv2/bn/mean/EMA, group1/block0/conv2/bn/variance/EMA, group1/block0/conv3/W, group1/block0/conv3/bn/gamma, group1/block0/conv3/bn/beta, group1/block0/conv3/bn/mean/EMA, group1/block0/conv3/bn/variance/EMA, group1/block0/convshortcut/W, group1/block0/convshortcut/bn/gamma, group1/block0/convshortcut/bn/beta, group1/block0/convshortcut/bn/mean/EMA, group1/block0/convshortcut/bn/variance/EMA, group1/block1/conv1/W, group1/block1/conv1/bn/gamma, group1/block1/conv1/bn/beta, group1/block1/conv1/bn/mean/EMA, group1/block1/conv1/bn/variance/EMA, group1/block1/conv2/W, group1/block1/conv2/bn/gamma, group1/block1/conv2/bn/beta, group1/block1/conv2/bn/mean/EMA, group1/block1/conv2/bn/variance/EMA, group1/block1/conv3/W, group1/block1/conv3/bn/gamma, group1/block1/conv3/bn/beta, group1/block1/conv3/bn/mean/EMA, group1/block1/conv3/bn/variance/EMA, group1/block2/conv1/W, group1/block2/conv1/bn/gamma, group1/block2/conv1/bn/beta, group1/block2/conv1/bn/mean/EMA, group1/block2/conv1/bn/variance/EMA, group1/block2/conv2/W, group1/block2/conv2/bn/gamma, group1/block2/conv2/bn/beta, group1/block2/conv2/bn/mean/EMA, group1/block2/conv2/bn/variance/EMA, group1/block2/conv3/W, group1/block2/conv3/bn/gamma, group1/block2/conv3/bn/beta, group1/block2/conv3/bn/mean/EMA, group1/block2/conv3/bn/variance/EMA, group1/block3/conv1/W, group1/block3/conv1/bn/gamma, group1/block3/conv1/bn/beta, group1/block3/conv1/bn/mean/EMA, group1/block3/conv1/bn/variance/EMA, group1/block3/conv2/W, group1/block3/conv2/bn/gamma, group1/block3/conv2/bn/beta, group1/block3/conv2/bn/mean/EMA, group1/block3/conv2/bn/variance/EMA, group1/block3/conv3/W, group1/block3/conv3/bn/gamma, group1/block3/conv3/bn/beta, group1/block3/conv3/bn/mean/EMA, group1/block3/conv3/bn/variance/EMA, group2/block0/conv1/W, group2/block0/conv1/bn/gamma, group2/block0/conv1/bn/beta, group2/block0/conv1/bn/mean/EMA, group2/block0/conv1/bn/variance/EMA, group2/block0/conv2/W, group2/block0/conv2/bn/gamma, group2/block0/conv2/bn/beta, group2/block0/conv2/bn/mean/EMA, group2/block0/conv2/bn/variance/EMA, group2/block0/conv3/W, group2/block0/conv3/bn/gamma, group2/block0/conv3/bn/beta, group2/block0/conv3/bn/mean/EMA, group2/block0/conv3/bn/variance/EMA, group2/block0/convshortcut/W, group2/block0/convshortcut/bn/gamma, group2/block0/convshortcut/bn/beta, group2/block0/convshortcut/bn/mean/EMA, group2/block0/convshortcut/bn/variance/EMA, group2/block1/conv1/W, group2/block1/conv1/bn/gamma, group2/block1/conv1/bn/beta, group2/block1/conv1/bn/mean/EMA, group2/block1/conv1/bn/variance/EMA, group2/block1/conv2/W, group2/block1/conv2/bn/gamma, group2/block1/conv2/bn/beta, group2/block1/conv2/bn/mean/EMA, group2/block1/conv2/bn/variance/EMA, group2/block1/conv3/W, group2/block1/conv3/bn/gamma, group2/block1/conv3/bn/beta, group2/block1/conv3/bn/mean/EMA, group2/block1/conv3/bn/variance/EMA, group2/block2/conv1/W, group2/block2/conv1/bn/gamma, group2/block2/conv1/bn/beta, group2/block2/conv1/bn/mean/EMA, group2/block2/conv1/bn/variance/EMA, group2/block2/conv2/W, group2/block2/conv2/bn/gamma, group2/block2/conv2/bn/beta, group2/block2/conv2/bn/mean/EMA, group2/block2/conv2/bn/variance/EMA, group2/block2/conv3/W, group2/block2/conv3/bn/gamma, group2/block2/conv3/bn/beta, group2/block2/conv3/bn/mean/EMA, group2/block2/conv3/bn/variance/EMA, group2/block3/conv1/W, group2/block3/conv1/bn/gamma, group2/block3/conv1/bn/beta, group2/block3/conv1/bn/mean/EMA, group2/block3/conv1/bn/variance/EMA, group2/block3/conv2/W, group2/block3/conv2/bn/gamma, group2/block3/conv2/bn/beta, group2/block3/conv2/bn/mean/EMA, group2/block3/conv2/bn/variance/EMA, group2/block3/conv3/W, group2/block3/conv3/bn/gamma, group2/block3/conv3/bn/beta, group2/block3/conv3/bn/mean/EMA, group2/block3/conv3/bn/variance/EMA, group2/block4/conv1/W, group2/block4/conv1/bn/gamma, group2/block4/conv1/bn/beta, group2/block4/conv1/bn/mean/EMA, group2/block4/conv1/bn/variance/EMA, group2/block4/conv2/W, group2/block4/conv2/bn/gamma, group2/block4/conv2/bn/beta, group2/block4/conv2/bn/mean/EMA, group2/block4/conv2/bn/variance/EMA, group2/block4/conv3/W, group2/block4/conv3/bn/gamma, group2/block4/conv3/bn/beta, group2/block4/conv3/bn/mean/EMA, group2/block4/conv3/bn/variance/EMA, group2/block5/conv1/W, group2/block5/conv1/bn/gamma, group2/block5/conv1/bn/beta, group2/block5/conv1/bn/mean/EMA, group2/block5/conv1/bn/variance/EMA, group2/block5/conv2/W, group2/block5/conv2/bn/gamma, group2/block5/conv2/bn/beta, group2/block5/conv2/bn/mean/EMA, group2/block5/conv2/bn/variance/EMA, group2/block5/conv3/W, group2/block5/conv3/bn/gamma, group2/block5/conv3/bn/beta, group2/block5/conv3/bn/mean/EMA, group2/block5/conv3/bn/variance/EMA, group3/block0/conv1/W, group3/block0/conv1/bn/gamma, group3/block0/conv1/bn/beta, group3/block0/conv1/bn/mean/EMA, group3/block0/conv1/bn/variance/EMA, group3/block0/conv2/W, group3/block0/conv2/bn/gamma, group3/block0/conv2/bn/beta, group3/block0/conv2/bn/mean/EMA, group3/block0/conv2/bn/variance/EMA, group3/block0/conv3/W, group3/block0/conv3/bn/gamma, group3/block0/conv3/bn/beta, group3/block0/conv3/bn/mean/EMA, group3/block0/conv3/bn/variance/EMA, group3/block0/convshortcut/W, group3/block0/convshortcut/bn/gamma, group3/block0/convshortcut/bn/beta, group3/block0/convshortcut/bn/mean/EMA, group3/block0/convshortcut/bn/variance/EMA, group3/block1/conv1/W, group3/block1/conv1/bn/gamma, group3/block1/conv1/bn/beta, group3/block1/conv1/bn/mean/EMA, group3/block1/conv1/bn/variance/EMA, group3/block1/conv2/W, group3/block1/conv2/bn/gamma, group3/block1/conv2/bn/beta, group3/block1/conv2/bn/mean/EMA, group3/block1/conv2/bn/variance/EMA, group3/block1/conv3/W, group3/block1/conv3/bn/gamma, group3/block1/conv3/bn/beta, group3/block1/conv3/bn/mean/EMA, group3/block1/conv3/bn/variance/EMA, group3/block2/conv1/W, group3/block2/conv1/bn/gamma, group3/block2/conv1/bn/beta, group3/block2/conv1/bn/mean/EMA, group3/block2/conv1/bn/variance/EMA, group3/block2/conv2/W, group3/block2/conv2/bn/gamma, group3/block2/conv2/bn/beta, group3/block2/conv2/bn/mean/EMA, group3/block2/conv2/bn/variance/EMA, group3/block2/conv3/W, group3/block2/conv3/bn/gamma, group3/block2/conv3/bn/beta, group3/block2/conv3/bn/mean/EMA, group3/block2/conv3/bn/variance/EMA\n",
            "\u001b[32m[1107 08:04:44 @sessinit.py:87]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The following variables are in the graph, but not found in the dict: fastrcnn/fc6/W, fastrcnn/fc6/b, fastrcnn/fc7/W, fastrcnn/fc7/b, fastrcnn/outputs/box/W, fastrcnn/outputs/box/b, fastrcnn/outputs/class/W, fastrcnn/outputs/class/b, fpn/lateral_1x1_c2/W, fpn/lateral_1x1_c2/b, fpn/lateral_1x1_c3/W, fpn/lateral_1x1_c3/b, fpn/lateral_1x1_c4/W, fpn/lateral_1x1_c4/b, fpn/lateral_1x1_c5/W, fpn/lateral_1x1_c5/b, fpn/posthoc_3x3_p2/W, fpn/posthoc_3x3_p2/b, fpn/posthoc_3x3_p3/W, fpn/posthoc_3x3_p3/b, fpn/posthoc_3x3_p4/W, fpn/posthoc_3x3_p4/b, fpn/posthoc_3x3_p5/W, fpn/posthoc_3x3_p5/b, global_step, learning_rate, rpn/box/W, rpn/box/b, rpn/class/W, rpn/class/b, rpn/conv0/W, rpn/conv0/b\n",
            "\u001b[32m[1107 08:04:44 @sessinit.py:87]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The following variables are in the dict, but not found in the graph: linear/W, linear/b\n",
            "\u001b[32m[1107 08:04:44 @sessinit.py:236]\u001b[0m Restoring 265 variables from dict ...\n",
            "\u001b[32m[1107 08:04:44 @base.py:243]\u001b[0m Graph Finalized.\n",
            "\u001b[32m[1107 08:04:44 @concurrency.py:37]\u001b[0m Starting EnqueueThread QueueInput/input_queue ...\n",
            "\u001b[32m[1107 08:04:54 @param.py:158]\u001b[0m [HyperParamSetter] At global_step=0, learning_rate is set to 0.003300\n",
            "\u001b[32m[1107 08:04:56 @eval.py:222]\u001b[0m [EvalCallback] Will evaluate every 25 epochs\n",
            "\u001b[32m[1107 08:04:56 @base.py:275]\u001b[0m Start Epoch 1 ...\n",
            "  0% 0/500 [00:00<?, ?it/s]2019-11-07 08:05:06.247748: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-11-07 08:05:07.041433: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "\u001b[32m[1107 08:05:13 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=1, learning_rate changes from 0.003300 to 0.003307\n",
            "100% 500/500 [03:55<00:00,  2.13it/s]\n",
            "\u001b[32m[1107 08:08:51 @base.py:285]\u001b[0m Epoch 1 (global_step 500) finished, time:3 minutes 55 seconds.\n",
            "\u001b[32m[1107 08:08:51 @misc.py:109]\u001b[0m Estimated Time Left: 7 hours 15 minutes 22 seconds\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m GPUUtil/0: 73.098\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m PeakMemory(MB)/gpu:0: 3866\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m QueueInput/queue_size: 50\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m fastrcnn_losses/box_loss: 0.32153\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m fastrcnn_losses/label_loss: 0.3109\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m fastrcnn_losses/label_metrics/accuracy: 0.87331\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m fastrcnn_losses/label_metrics/false_negative: 0.24064\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m fastrcnn_losses/label_metrics/fg_accuracy: 0.74716\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m fastrcnn_losses/num_fg_label: 125.72\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m learning_rate: 0.0066433\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level2: 437.53\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level3: 27.882\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level4: 44.882\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level5: 1.7044\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/box_loss: 0.16846\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/label_loss: 0.14529\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level2/box_loss: 0.16268\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level2/label_loss: 0.12323\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level2/label_metrics/precision_th0.1: 0.84743\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level2/label_metrics/precision_th0.2: 0.87815\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level2/label_metrics/precision_th0.5: 0.94177\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level2/label_metrics/recall_th0.1: 0.99944\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level2/label_metrics/recall_th0.2: 0.99821\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level2/label_metrics/recall_th0.5: 0.94058\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level2/num_pos_anchor: 99.062\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level2/num_valid_anchor: 219.78\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level3/box_loss: 0.0053459\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level3/label_loss: 0.016028\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level3/label_metrics/precision_th0.1: 0.48206\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level3/label_metrics/precision_th0.2: 0.6203\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level3/label_metrics/precision_th0.5: 0.62666\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level3/label_metrics/recall_th0.1: 0.80028\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level3/label_metrics/recall_th0.2: 0.77203\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level3/label_metrics/recall_th0.5: 0.43006\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level3/num_pos_anchor: 3.3097\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level3/num_valid_anchor: 29.594\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level4/box_loss: 0.00041393\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level4/label_loss: 0.0038921\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level4/label_metrics/precision_th0.1: 0.093693\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level4/label_metrics/precision_th0.2: 0.37038\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level4/label_metrics/precision_th0.5: 0.5\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level4/label_metrics/recall_th0.1: 0.55108\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level4/label_metrics/recall_th0.2: 0.50003\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level4/label_metrics/recall_th0.5: 0.44893\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level4/num_pos_anchor: 0.23939\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level4/num_valid_anchor: 5.7956\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level5/box_loss: 1.8884e-05\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level5/label_loss: 0.0021367\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level5/label_metrics/precision_th0.1: 0.30607\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level5/label_metrics/precision_th0.2: 0.30607\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level5/label_metrics/precision_th0.5: 0.42553\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level5/label_metrics/recall_th0.1: 0.52256\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level5/label_metrics/recall_th0.2: 0.52256\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level5/label_metrics/recall_th0.5: 0.52256\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level5/num_pos_anchor: 0.045131\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level5/num_valid_anchor: 0.8286\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level6/box_loss: 0\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level6/label_loss: 1.0994e-06\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level6/label_metrics/precision_th0.1: 0.49983\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level6/label_metrics/precision_th0.2: 0.49983\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level6/label_metrics/precision_th0.5: 0.49983\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level6/label_metrics/recall_th0.1: 0.5\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level6/label_metrics/recall_th0.2: 0.5\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level6/label_metrics/recall_th0.5: 0.5\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level6/num_pos_anchor: 0\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m rpn_losses/level6/num_valid_anchor: 0.00033617\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m sample_fast_rcnn_targets/num_bg: 386.28\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m sample_fast_rcnn_targets/num_fg: 125.72\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m sample_fast_rcnn_targets/proposal_metrics/best_iou_per_gt: 0.52939\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.3: 0.9245\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.5: 0.59018\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m total_cost: 1.4166\n",
            "\u001b[32m[1107 08:08:51 @monitor.py:474]\u001b[0m wd_cost: 0.47042\n",
            "\u001b[32m[1107 08:08:51 @base.py:275]\u001b[0m Start Epoch 2 ...\n",
            "  0% 0/500 [00:00<?, ?it/s]\u001b[32m[1107 08:08:51 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=501, learning_rate changes from 0.006650 to 0.006657\n",
            "100% 500/500 [03:30<00:00,  2.38it/s]\n",
            "\u001b[32m[1107 08:12:21 @base.py:285]\u001b[0m Epoch 2 (global_step 1000) finished, time:3 minutes 30 seconds.\n",
            "\u001b[32m[1107 08:12:21 @param.py:158]\u001b[0m [HyperParamSetter] At global_step=1000, learning_rate is set to 0.010000\n",
            "\u001b[32m[1107 08:12:21 @misc.py:109]\u001b[0m Estimated Time Left: 6 hours 48 minutes 39 seconds\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m GPUUtil/0: 80.486\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m PeakMemory(MB)/gpu:0: 3866\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m QueueInput/queue_size: 50\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m fastrcnn_losses/box_loss: 0.32861\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m fastrcnn_losses/label_loss: 0.33622\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m fastrcnn_losses/label_metrics/accuracy: 0.84154\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m fastrcnn_losses/label_metrics/false_negative: 0.22303\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m fastrcnn_losses/label_metrics/fg_accuracy: 0.76464\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m fastrcnn_losses/num_fg_label: 127.88\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m learning_rate: 0.0099933\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level2: 429.39\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level3: 45.845\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level4: 36.052\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level5: 0.71321\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/box_loss: 0.16009\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/label_loss: 0.12332\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level2/box_loss: 0.15609\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level2/label_loss: 0.1115\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level2/label_metrics/precision_th0.1: 0.853\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level2/label_metrics/precision_th0.2: 0.88158\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level2/label_metrics/precision_th0.5: 0.9406\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level2/label_metrics/recall_th0.1: 0.99854\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level2/label_metrics/recall_th0.2: 0.99673\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level2/label_metrics/recall_th0.5: 0.98545\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level2/num_pos_anchor: 111.49\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level2/num_valid_anchor: 223.17\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level3/box_loss: 0.0029714\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level3/label_loss: 0.0072079\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level3/label_metrics/precision_th0.1: 0.63267\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level3/label_metrics/precision_th0.2: 0.70468\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level3/label_metrics/precision_th0.5: 0.74711\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level3/label_metrics/recall_th0.1: 0.80708\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level3/label_metrics/recall_th0.2: 0.8009\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level3/label_metrics/recall_th0.5: 0.70605\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level3/num_pos_anchor: 2.2931\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level3/num_valid_anchor: 26.24\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level4/box_loss: 0.00044928\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level4/label_loss: 0.002821\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level4/label_metrics/precision_th0.1: 0.39758\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level4/label_metrics/precision_th0.2: 0.55479\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level4/label_metrics/precision_th0.5: 0.58481\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level4/label_metrics/recall_th0.1: 0.58235\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level4/label_metrics/recall_th0.2: 0.57664\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level4/label_metrics/recall_th0.5: 0.52571\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level4/num_pos_anchor: 0.51939\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level4/num_valid_anchor: 5.7348\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level5/box_loss: 0.00057466\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level5/label_loss: 0.0017732\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level5/label_metrics/precision_th0.1: 0.30166\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level5/label_metrics/precision_th0.2: 0.30473\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level5/label_metrics/precision_th0.5: 0.50136\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level5/label_metrics/recall_th0.1: 0.525\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level5/label_metrics/recall_th0.2: 0.525\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level5/label_metrics/recall_th0.5: 0.5125\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level5/num_pos_anchor: 0.20001\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level5/num_valid_anchor: 0.84218\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level6/box_loss: 0\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level6/label_loss: 2.2272e-05\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level6/label_metrics/precision_th0.1: 0.49522\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level6/label_metrics/precision_th0.2: 0.49522\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level6/label_metrics/precision_th0.5: 0.5\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level6/label_metrics/recall_th0.1: 0.5\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level6/label_metrics/recall_th0.2: 0.5\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level6/label_metrics/recall_th0.5: 0.5\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level6/num_pos_anchor: 0\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m rpn_losses/level6/num_valid_anchor: 0.0095647\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m sample_fast_rcnn_targets/num_bg: 384.12\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m sample_fast_rcnn_targets/num_fg: 127.88\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m sample_fast_rcnn_targets/proposal_metrics/best_iou_per_gt: 0.6104\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.3: 0.97666\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.5: 0.8143\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m total_cost: 1.4182\n",
            "\u001b[32m[1107 08:12:22 @monitor.py:474]\u001b[0m wd_cost: 0.47\n",
            "\u001b[32m[1107 08:12:22 @base.py:275]\u001b[0m Start Epoch 3 ...\n",
            " 33% 166/500 [01:07<02:16,  2.44it/s]\u001b[32m[1107 08:13:30 @base.py:293]\u001b[0m Detected Ctrl-C and exiting main loop.\n",
            " 33% 166/500 [01:07<02:16,  2.44it/s]\n",
            "2019-11-07 08:13:30.735903: W tensorflow/core/kernels/queue_base.cc:277] _0_QueueInput/input_queue: Skipping cancelled enqueue attempt with queue not closed\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 547, in <module>\n",
            "    launch_train_with_config(traincfg, trainer)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorpack/train/interface.py\", line 101, in launch_train_with_config\n",
            "    extra_callbacks=config.extra_callbacks)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorpack/train/base.py\", line 344, in train_with_defaults\n",
            "    steps_per_epoch, starting_epoch, max_epoch)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorpack/train/base.py\", line 316, in train\n",
            "    self.main_loop(steps_per_epoch, starting_epoch, max_epoch)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorpack/utils/argtools.py\", line 176, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorpack/train/base.py\", line 281, in main_loop\n",
            "    self.run_step()  # implemented by subclass\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorpack/train/base.py\", line 181, in run_step\n",
            "    self.hooked_sess.run(self.train_op)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 754, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1259, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1345, in run\n",
            "    return self._sess.run(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1418, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1176, in run\n",
            "    return self._sess.run(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 956, in run\n",
            "    run_metadata_ptr)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\n",
            "    feed_dict_tensor, options, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n",
            "    run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n",
            "    return fn(*args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n",
            "    target_list, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n",
            "    run_metadata)\n",
            "KeyboardInterrupt\n",
            "MultiProcessMapDataZMQ successfully cleaned-up.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2ZAduGGQARc",
        "colab_type": "code",
        "outputId": "2d615d41-4938-4a8d-9015-5722f5b0ded0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!ls ../train_logs"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "events.out.tfevents.1573113898.a617eb4da0b5  log.log\n",
            "graph-1107-080444.meta\t\t\t     stats.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnUz9sgJZRHK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "less ../train_logs/log.log"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvHfYov878SR",
        "colab_type": "text"
      },
      "source": [
        "You will need to fill out the input image path and the path to the trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmubOEEBZbFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python train.py --predict xxx.png \\\n",
        "                --load ../train_logs/model-xxxx.data-00000-of-00001 \\\n",
        "                --config MODE_MASK=False MODE_FPN=True \\\n",
        "                        DATA.BASEDIR=../data \\\n",
        "        BACKBONE.WEIGHTS=/tmp/weights/pretrained/ImageNet-R50-AlignPadding.npz \\\n",
        "        DATA.TRAIN=train_B1_1000h DATA.VAL=val_B1_1000h \\\n",
        "        PREPROC.TRAIN_SHORT_EDGE_SIZE=600,600 \\\n",
        "        PREPROC.TEST_SHORT_EDGE_SIZE=600 \\\n",
        "\t      TEST.RESULT_SCORE_THRESH_VIS=0.7 \\\n",
        "\t      TEST.RESULT_SCORE_THRESH=0.7 \\\n",
        "        DATA.CLASS_NAMES=1,2,3\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}